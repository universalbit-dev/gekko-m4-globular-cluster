# Chess Log Processing and JSON Upload Documentation

## Overview

This documentation describes the workflow, file structure, and usage of the chess log processing and uploading system for the [`gekko-m4-globular-cluster`](https://github.com/universalbit-dev/gekko-m4-globular-cluster) project. The focus is on the files and pipeline found in the [`logs/json`](https://github.com/universalbit-dev/gekko-m4-globular-cluster/tree/master/logs/json) directory, which facilitate the extraction, transformation, and periodic uploading of chess game data.

## Context

- **Purpose:** To capture, filter, and maintain a rolling log of chess game events (specifically those labeled "Random Game Of Chess") generated by the Gekko-M4 system, and to upload this data periodically to [jsonbin.io](https://jsonbin.io/) for cloud storage, sharing, and further analysis.
- **Application:** Useful in financial analytics, automated chess simulations, and backtesting environments where reproducible logs and data snapshots are critical.

### File Descriptions

- **randomchess.json**
  - A rolling JSON array containing filtered chess log entries.
  - Kept at a maximum of 1MB for efficiency and easy cloud upload.
  - Continuously updated by the log processor, always reflecting the latest "Random Game Of Chess" events.

- **realTimeChessProcessor.js**
  - Node.js script that listens for JSON-formatted logs (e.g., from PM2).
  - Filters entries to collect only those containing "Random Game Of Chess".
  - Maintains and trims `randomchess.json` to ensure it never exceeds 1MB.
  - Designed to be run as part of a pipeline:
    ```bash
    pm2 logs --json | node realTimeChessProcessor.js
    ```
  - No external dependencies required.

- **jsonbin_randomchess.js**
  - Node.js script that uploads the contents of `randomchess.json` to jsonbin.io every hour using a scheduled cron job.
  - Requires the following npm packages: `node-fetch`, `fs-extra`, `node-cron`.
  - Set your jsonbin.io access key in the script before running.
  - Intended to be run continuously for automated uploads.

## Pipeline Usage

1. **Log Extraction and Filtering**
   - Run your service/application under PM2.
   - Pipe PM2's JSON logs to the processor:
     ```bash
     pm2 logs --json | node realTimeChessProcessor.js
     ```
   - `realTimeChessProcessor.js` will create and update `randomchess.json` with relevant chess event data.

2. **Automated Upload**
   - In a separate process, run:
     ```bash
     node jsonbin_randomchess.js
     ```
   - This will upload the latest `randomchess.json` to your jsonbin.io account every hour.

## About jsonbin.io

[jsonbin.io](https://jsonbin.io/) is a simple, secure web service for storing, retrieving, and managing JSON data in the cloud via HTTP API. It is ideal for sharing structured data snapshots, backups, or logs needed for downstream workflows or analysis.

## Example Use Cases

- **Financial and Chess Strategy Analysis:** Retain and share reproducible logs of chess simulations for backtesting strategies.
- **Data Synchronization:** Ensure the latest simulation results are always available in the cloud for collaborators or automated tools.
- **Archival:** Maintain a compact, rolling archive of chess games for audit or research.

## Requirements

- [Node.js](https://nodejs.org/en)

## Author

- universalbit-dev

---
