#!/usr/bin/env node
/**
 * tools/evaluation/evaluate.js
 *
 * Purpose:
 * - Process OHLCV source files generated by explorer.js:
 *     ohlcv_ccxt_data_1m.json, ohlcv_ccxt_data_5m.json, ohlcv_ccxt_data_15m.json, ohlcv_ccxt_data_1h.json
 *   Each file is expected to be an array of objects with keys:
 *     { symbol, exchange, timestamp, open, high, low, close, volume, ohlcvCandleSize, source_timeframe, ... }
 *
 * - For each timeframe file:
 *     - Validate & normalize rows
 *     - Run tests from evaluate.json
 *     - Produce per-timeframe output: <outputBase>.<tf>.json (e.g. evaluate_results.1m.json)
 * - Also produce combined flattened output at outputPath (evaluate_results.json)
 * - Options:
 *     --dry-run   : don't write files, only print results
 *     --verbose   : print extra debug logs
 *     --watch ms  : run continuously every ms (same behavior as earlier)
 *
 * - Environment:
 *     EVALUATE_CONFIG: override evaluate.json path
 *     EVALUATE_DATA: override dataPath
 *     DELETE_AUGMENTED=1 : remove evaluate_results_augmented.json after writing combined output
 *
 * Notes:
 * - This implementation intentionally only processes files matching the explorer naming:
 *     ohlcv_ccxt_data*.json
 *   to avoid confusion with other JSON files in the folder.
 */
const fs = require('fs');
const path = require('path');
const util = require('util');

require('dotenv').config({ path: path.resolve(__dirname, '../../.env') });

const VERBOSE = process.argv.includes('--verbose');
const DRY_RUN = process.argv.includes('--dry-run');

function vlog(...a) { if (VERBOSE) console.log('[EVALUATE]', ...a); }
function log(...a) { console.log('[EVALUATE]', ...a); }
function warn(...a) { console.warn('[EVALUATE][WARN]', ...a); }
function err(...a) { console.error('[EVALUATE][ERROR]', ...a); }

function safeReadJson(fp) {
  try {
    if (!fp || !fs.existsSync(fp)) return null;
    const raw = fs.readFileSync(fp, 'utf8');
    if (!raw) return null;
    return JSON.parse(raw);
  } catch (e) {
    err('safeReadJson parse error for', fp, e && e.message ? e.message : e);
    return null;
  }
}

function safeWriteJsonAtomic(fp, obj) {
  try {
    const tmp = fp + '.tmp';
    fs.mkdirSync(path.dirname(fp), { recursive: true });
    fs.writeFileSync(tmp, JSON.stringify(obj, null, 2), 'utf8');
    fs.renameSync(tmp, fp);
    return true;
  } catch (e) {
    err('safeWriteJsonAtomic failed for', fp, e && e.message ? e.message : e);
    return false;
  }
}

function fileExists(fp) {
  try { return fs.existsSync(fp); } catch { return false; }
}

function loadEvaluateConfig(cfgPath) {
  const cfg = safeReadJson(cfgPath);
  if (!cfg) throw new Error(`evaluate.json config not found or invalid JSON at ${cfgPath}`);
  if (!cfg.tests || !Array.isArray(cfg.tests) || !cfg.tests.length) throw new Error("evaluate.json 'tests' missing or empty");
  if (!cfg.dataPath || typeof cfg.dataPath !== 'string') throw new Error("evaluate.json 'dataPath' missing or invalid");
  return cfg;
}

// helpers to detect explorer files and timeframe
function isExplorerFileName(name) {
  return /^ohlcv_ccxt_data(?:_.*)?\.json$/i.test(path.basename(name));
}
function inferTfFromFilename(fn) {
  const base = path.basename(fn).toLowerCase();
  const known = ['1m','3m','5m','15m','30m','1h','2h','4h','6h','1d','1w'];
  for (const k of known) if (base.includes(k)) return k;
  return null;
}

// Normalize & validate rows produced by explorer.js
function normalizeRows(rawArr) {
  if (!Array.isArray(rawArr)) return [];
  const out = [];
  for (const r of rawArr) {
    if (!r || typeof r !== 'object') continue;
    const row = Object.assign({}, r);
    // coerce numeric strings to numbers
    ['timestamp','open','high','low','close','volume'].forEach(k=>{
      if (row[k] !== undefined && row[k] !== null && typeof row[k] === 'string') {
        const n = Number(row[k]);
        if (!Number.isNaN(n)) row[k] = n;
      }
    });
    // ensure numeric fields exist
    if (typeof row.timestamp !== 'number' || typeof row.open !== 'number' ||
        typeof row.high !== 'number' || typeof row.low !== 'number' ||
        typeof row.close !== 'number' || typeof row.volume !== 'number') {
      // skip invalid row
      vlog('skipping invalid row (missing numeric fields)', row && row.timestamp);
      continue;
    }
    // ensure timeframe field exists
    row.ohlcvCandleSize = row.ohlcvCandleSize || row.source_timeframe || row.timeframe || row.interval || null;
    out.push(row);
  }
  return out;
}

// scoring and evaluation functions (same as previous)
function absScore(values) { return values.reduce((acc, v) => acc + (v == null ? 0 : Math.abs(v)), 0); }
function profitScore(ohlcvArr, signals, params) {
  let position = 0, entry = 0, profit = 0;
  for (let i = 1; i < signals.length; ++i) {
    if (!position && params.buyLevel !== undefined && signals[i] < params.buyLevel) { position = 1; entry = ohlcvArr[i].close; }
    if (position && params.sellLevel !== undefined && signals[i] > params.sellLevel) { profit += ohlcvArr[i].close - entry; position = 0; }
  }
  if (position) profit += ohlcvArr[ohlcvArr.length - 1].close - entry;
  return profit;
}
function sharpeScore(returns) {
  if (!returns.length) return 0;
  const mean = returns.reduce((a, b) => a + b, 0) / returns.length;
  const variance = returns.reduce((a, b) => a + Math.pow(b - mean, 2), 0) / returns.length;
  const stddev = Math.sqrt(variance);
  return stddev === 0 ? 0 : mean / stddev;
}
function hitRateScore(trades) {
  if (!trades.length) return 0;
  const wins = trades.filter(t => t > 0).length;
  return wins / trades.length;
}
function simulateTrades(ohlcvArr, signals, params) {
  let position = 0, entry = 0, trades = [];
  for (let i = 1; i < signals.length; ++i) {
    if (!position && params.buyLevel !== undefined && signals[i] < params.buyLevel) { position = 1; entry = ohlcvArr[i].close; }
    if (position && params.sellLevel !== undefined && signals[i] > params.sellLevel) { trades.push(ohlcvArr[i].close - entry); position = 0; }
  }
  if (position) trades.push(ohlcvArr[ohlcvArr.length - 1].close - entry);
  return trades;
}

const scoringMethods = {
  abs: (candles, values, params) => absScore(values),
  profit: (candles, values, params) => profitScore(candles, values, params),
  sharpe: (candles, values, params) => {
    let returns = [];
    for (let i = 1; i < candles.length; ++i) returns.push((candles[i].close - candles[i - 1].close) / candles[i - 1].close);
    return sharpeScore(returns);
  },
  'hit-rate': (candles, values, params) => {
    const trades = simulateTrades(candles, values, params);
    return hitRateScore(trades);
  }
};

// lazy indicator require map like earlier implementations
const indicators = {
  rsi: () => require('./indicator/RSI.js'),
  atr: () => require('./indicator/ATR.js'),
  adx: () => require('./indicator/ADX.js'),
  dx:  () => require('./indicator/DX.js'),
  sma: () => require('./indicator/SMA.js'),
};

function evaluateFileWithConfig(candles, config, outPrefix = '') {
  if (!Array.isArray(candles) || candles.length === 0) {
    vlog(`${outPrefix} no candles to evaluate`);
    return [];
  }
  const results = [];
  for (const test of config.tests) {
    const indName = (test.indicator || '').toLowerCase();
    const params = test.params || {};
    const scoring = (test.scoring || 'abs').toLowerCase();
    const label = test.label || `${indName}:${JSON.stringify(params)}`;
    try {
      const indFactory = indicators[indName];
      if (!indFactory) {
        warn(`${outPrefix} unknown indicator '${indName}', skipping test`);
        continue;
      }
      const IndClass = indFactory();
      const indicator = new IndClass(params);

      const values = [];
      for (const c of candles) {
        if (indName === 'rsi' || indName === 'sma') indicator.update && indicator.update(c.close);
        else indicator.update && indicator.update(c);
        const v = indicator.value ?? indicator.result ?? null;
        values.push(v);
      }

      const scorer = scoringMethods[scoring] || scoringMethods.abs;
      const score = scorer(candles, values, params);

      const extra = {};
      if (scoring === 'hit-rate') {
        const trades = simulateTrades(candles, values, params);
        extra.totalTrades = trades.length;
        extra.wins = trades.filter(t => t > 0).length;
        extra.losses = trades.filter(t => t <= 0).length;
      }

      results.push({
        indicator: indName,
        label,
        params,
        scoring,
        score,
        lastValue: values[values.length - 1],
        timestamp: candles[candles.length - 1]?.timestamp ?? Date.now(),
        ...extra
      });
    } catch (e) {
      warn(`${outPrefix} test failed for ${indName} ${util.inspect(test.params)}:`, e && e.message ? e.message : e);
    }
  }
  return results;
}

// Main runner
function runOnce(configPath) {
  try {
    const cfgPath = configPath || process.env.EVALUATE_CONFIG || path.join(__dirname, 'evaluate.json');
    if (!fileExists(cfgPath)) { warn('evaluate.json not found at', cfgPath); return null; }
    const config = loadEvaluateConfig(cfgPath);

    const dataPath = path.resolve(process.env.EVALUATE_DATA || path.resolve(__dirname, config.dataPath));
    if (!fileExists(dataPath)) { warn('dataPath not found at', dataPath); return null; }

    // collect explorer-style files only
    const dir = fs.statSync(dataPath).isDirectory() ? dataPath : path.dirname(dataPath);
    const candidates = fs.readdirSync(dir)
      .filter(f => isExplorerFileName(f))
      .map(f => path.join(dir, f));

    if (!candidates.length) { warn('No explorer OHLCV files found in', dir); return null; }
    vlog('discover files:', candidates);

    const perTfMap = {}; // tf -> array of results (annotated)
    const combinedFlatten = [];

    for (const f of candidates) {
      const raw = safeReadJson(f);
      if (!raw) { vlog('empty or unparsable file', f); continue; }
      let rows = Array.isArray(raw) ? raw : (raw.data || raw.candles || raw.ohlcv || Object.values(raw).find(Array.isArray) || null);
      if (!rows) { vlog('file has no array at root or known keys', f); continue; }

      rows = normalizeRows(rows);
      if (!rows.length) { vlog('no valid rows after normalization from', f); continue; }

      // infer timeframe: prefer each row's ohlcvCandleSize if present; else filename
      const tfFromRows = rows[0].ohlcvCandleSize || rows[0].source_timeframe || rows[0].timeframe || null;
      const tfFromName = inferTfFromFilename(f);
      const tf = tfFromRows || tfFromName || path.parse(f).name;
      vlog(`processing ${f} -> timeframe=${tf} rows=${rows.length}`);

      // If rows contain mixed timeframes, filter to those matching tf (if tfFromName)
      let candles = rows;
      if (tfFromName && !tfFromRows) {
        // when rows don't carry timeframe tag but filename does, keep all rows (assume file already per timeframe)
        candles = rows;
      } else if (tfFromRows) {
        candles = rows.filter(r => String(r.ohlcvCandleSize) === String(tf) || String(r.source_timeframe) === String(tf) || String(r.timeframe) === String(tf));
        if (!candles.length) {
          // fallback to using all rows if filtering removed everything
          candles = rows;
        }
      }

      // ensure time-order
      candles.sort((a,b)=>a.timestamp - b.timestamp);

      const prefix = `[file ${path.basename(f)}]`;
      const res = evaluateFileWithConfig(candles, config, prefix);
      if (!res.length) { vlog('no results from', f); continue; }

      // annotate with source and timeframe
      const annotated = res.map(r => Object.assign({}, r, { source: f, timeframe: tf }));
      if (!perTfMap[tf]) perTfMap[tf] = [];
      perTfMap[tf].push(...annotated);
      combinedFlatten.push(...annotated);
    }

    // write per-timeframe files adjacent to configured outputPath (or script dir)
    let combinedOutPath = null;
    if (config.outputPath) {
      const maybe = path.resolve(__dirname, config.outputPath);
      if (fileExists(maybe) && fs.statSync(maybe).isDirectory()) {
        combinedOutPath = path.join(maybe, 'evaluate_results.json');
      } else {
        fs.mkdirSync(path.dirname(maybe), { recursive: true });
        combinedOutPath = maybe;
      }
    } else {
      combinedOutPath = path.join(__dirname, 'evaluate_results.json');
    }

    // per-timeframe writes
    for (const [tf, arr] of Object.entries(perTfMap)) {
      const base = path.basename(combinedOutPath, '.json');
      const perPath = path.join(path.dirname(combinedOutPath), `${base}.${tf}.json`);
      if (VERBOSE || DRY_RUN) {
        log('Per-timeframe output', perPath, '->', arr.length, 'entries');
        if (VERBOSE) console.log(JSON.stringify(arr, null, 2));
      }
      if (!DRY_RUN) safeWriteJsonAtomic(perPath, arr);
    }

    // combined flattened output
    if (VERBOSE || DRY_RUN) {
      log('Combined output', combinedOutPath, '->', combinedFlatten.length, 'entries');
      if (VERBOSE) console.log(JSON.stringify(combinedFlatten, null, 2));
    }
    if (!DRY_RUN) {
      safeWriteJsonAtomic(combinedOutPath, combinedFlatten);
      log('Wrote combined evaluation output', combinedOutPath);
    }

    // optionally delete augmented evaluate_results file if requested
    if (!DRY_RUN && (process.env.DELETE_AUGMENTED === '1' || config.deleteAugmented === true)) {
      const augmented = path.join(path.dirname(combinedOutPath), 'evaluate_results_augmented.json');
      if (fileExists(augmented)) {
        try { fs.unlinkSync(augmented); log('Deleted augmented file', augmented); } catch (e) { warn('Failed to delete augmented file', augmented, e && e.message); }
      }
    }

    return { perTimeframe: perTfMap, combinedPath: combinedOutPath };
  } catch (e) {
    err('runOnce error:', e && e.message ? e.message : e);
    return null;
  }
}

// runner that supports --watch
async function main() {
  const intervalArg = parseInt((() => {
    const i = process.argv.indexOf('--watch');
    if (i === -1) return process.env.EVALUATE_INTERVAL_MS || '0';
    return process.argv[i+1] || '0';
  })(), 10) || 0;

  if (intervalArg > 0) {
    log(`Running continuously every ${intervalArg}ms`);
    runOnce();
    const id = setInterval(() => runOnce(), intervalArg);
    process.on('SIGINT', () => { log('SIGINT received, stopping'); clearInterval(id); process.exit(0); });
    process.on('SIGTERM', () => { log('SIGTERM received, stopping'); clearInterval(id); process.exit(0); });
  } else {
    runOnce();
  }
}

if (require.main === module) main();

module.exports = { runOnce };
